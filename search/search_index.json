{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"This site provides documentation around general software engineering behaviors and processes at the UKHO.","title":"Home"},{"location":"open-source-governance-checklist/","text":"Open Source Governance Checklist Identifer (e.g. repo name) Technical owner The lead responsible for the repo Description of functionality Must contain enough detail to allow assessment of whether it contains intellectual property that we need to protect. Security How has security been considered? Has application code been scanned with security tooling and issues corrected? This must be done for code supported by our SAST tooling Has the application been threat modelled during development and the evidence captured within TFS (or similar)? Threat modelling must be carried out for all application code, this evidence needs to be reviewed by expert or lead engineer Has the code been double-checked for security credentials, keys etc.? Give details of who has double-checked the code Is a disclosure process in place and linked from the codebase? Use the standard disclose text Quality How has code quality been considered? Does the quality of the code reflect our ambitions for high quality code, in terms of being clean, well-tested etc. Correct answer = yes! Has all code been reviewed? Correct answer = yes! Has the open-sourced codebase had its history removed? If not, have all check-in comments been reviewed? Describe the steps taken to prevent inadvertent disclosed in comments / etc. Does the codebase contain all documentation and configuration elements required to build and verify the software? A user should be able to build / run tests etc. based on what is in the repo Contributions Has the handling of contributions considered? Are contributions explicitly encouraged in the codebase For example, have you enabled the use of issues and provided a CONTRIBUTING.md? Think very carefully before inviting change, as you will then have to answer 'yes' to the next two questions Is a process for responding to issues defined? Describe in detail the process by which you are going to ensure that issues are responded to in a timely manner How is this process resourced? Describe how you have made sure that time is available to carry out the process described above. For example, has the relevant manager agreed for time for time to spent on this?","title":"Open Source Governance Checklist"},{"location":"open-source-governance-checklist/#open-source-governance-checklist","text":"","title":"Open Source Governance Checklist"},{"location":"open-source-governance-checklist/#identifer","text":"(e.g. repo name)","title":"Identifer"},{"location":"open-source-governance-checklist/#technical-owner","text":"The lead responsible for the repo","title":"Technical owner"},{"location":"open-source-governance-checklist/#description-of-functionality","text":"Must contain enough detail to allow assessment of whether it contains intellectual property that we need to protect.","title":"Description of functionality"},{"location":"open-source-governance-checklist/#security","text":"How has security been considered? Has application code been scanned with security tooling and issues corrected? This must be done for code supported by our SAST tooling Has the application been threat modelled during development and the evidence captured within TFS (or similar)? Threat modelling must be carried out for all application code, this evidence needs to be reviewed by expert or lead engineer Has the code been double-checked for security credentials, keys etc.? Give details of who has double-checked the code Is a disclosure process in place and linked from the codebase? Use the standard disclose text","title":"Security"},{"location":"open-source-governance-checklist/#quality","text":"How has code quality been considered? Does the quality of the code reflect our ambitions for high quality code, in terms of being clean, well-tested etc. Correct answer = yes! Has all code been reviewed? Correct answer = yes! Has the open-sourced codebase had its history removed? If not, have all check-in comments been reviewed? Describe the steps taken to prevent inadvertent disclosed in comments / etc. Does the codebase contain all documentation and configuration elements required to build and verify the software? A user should be able to build / run tests etc. based on what is in the repo","title":"Quality"},{"location":"open-source-governance-checklist/#contributions","text":"Has the handling of contributions considered? Are contributions explicitly encouraged in the codebase For example, have you enabled the use of issues and provided a CONTRIBUTING.md? Think very carefully before inviting change, as you will then have to answer 'yes' to the next two questions Is a process for responding to issues defined? Describe in detail the process by which you are going to ensure that issues are responded to in a timely manner How is this process resourced? Describe how you have made sure that time is available to carry out the process described above. For example, has the relevant manager agreed for time for time to spent on this?","title":"Contributions"},{"location":"linux-workstations/","text":"Introduction This page attempts to outline how you can set up your linux workstation VM to run under VMWare Player Pro V15.0.2 or greater. Obtaining VMWare player If your laptop doesn't have VMware player installed, in the first instance open Software center from the start menu and see if it is available. If it is, install it from here. If it is not available for you in Software Center, speak to service desk (or ideally Matt Page, as he managed this rollout originally) to have this added to your software center. Obtaining the VM image The first step of the process is to access the image which is held on: \\\\\\\\business.ukho.gov.uk\\dfs\\Prod_Prod\\Mint\\OVF Image U:\\Prod_Prod\\Mint\\OVF Image and copy this directory to your laptop. Once copied, start up VMware Player Pro and on the \"Home Screen\" select the option \"Open a Virtual Machine\": Please use the file browser displayed to select the location where the image was copied. You will recieve a dialog referring to a mismatch of versions, this is a known bug in VMWare workstation, press Retry and the process will continue. You will be asked for a name and a storage path - please ensure that the name of the VM image is: UKHO CentOS 7 Please ensure that the storage path of the VM image is: C:\\VirtualMachines\\DevVM Danger It is important that the specified location is used for compliance with SyOps! Settings for the VM image Ensure the 'tab' for the virtual machine in the UI is selected and click on the 'Edit Virtual Machine Settings' link on the left-hand-side of the page: In the window displayed, select the 'Network Adapter' entry on the left hand side. In the right hand side of the same window, ensure that the following settings are selected under \"Network connection\": \"Bridged\" mode is selected Replicate physical network connection state is selected. Click OK when done. Installation - Initial Packages Start-up the Virtual Machine by selecting the \"Power On\" (Ctrl+B) option. You will shortly see a screen having the option \"Install Centos 7 - With Hydro Kickstart\". Press Enter to continue: You will then see a screen which displays \"Press to start the installation process\" - either press Enter (or wait and the install should start automatically. This starts the kickstart installation process. After some minutes (Approx. 7mins, Go grab a lengthy coffee/tea/soft drink) you should see the following: Press return. You will get a message box stating that the machine has halted. Select the \"Restart Guest\" option (or press Ctrl+R) on the VM power settings. Warning Don't try this on UKHO_LAPTOPS wifi, as the setup will not be able to access GitHub After a few minutes the VM should boot and you should be presented with a login prompt: Enter the following: For username: root For password: Example joe.bloggs jane.doe Username constraints The username must be: Lower-case Alphabetic No spaces Next, you will be asked for your full name, which should be alphabetic Next, you will be asked for your password: Warning There are restrictions on the password you can use; passwords which are too lenient will be rejected. The set of interactions (for a user named jane.doe) might look as follows: The installation process will then continue, and you should see a login manager displayed after some time: Press space, this will display a set of users you can log in as (initially, this is the user you created earlier): Login by selecting the name of the user you entered earlier and enter the password, you should be presented with a screen as follows: Initially, this looks a little spartan! You can get an initial desktop created by selecting the 'Use Default Config' option - you should then see something as follows: Installing development utils Once you have logged in, if you wish to install maven, Java 8 Sdk and Yarn please go to a terminal and type: cd ~/linux-workstation/ansible sudo ansible-playbook -i inventories/laptop-vm/hosts --vault-password-file=$HOME/.config/linux-workstation/.vaultpass development.yml This should then install the basic utilities needed. Known Issues Bug Currently, the VPN on the Linux VM has an issue if you do the following: Suspend the Linux VM when the laptop is connected to the network via USB-C Resume the Linux VM when the laptop is connected to the network via WiFi Or: Suspend the Linux VM when the laptop is connected to the network via WiFi Resume the Linux VM when the laptop is connected to the network via USB-C Alternatively, keeping the VM un-suspended whilst changing networks avoids this scenario. The issue is that the VPN on the Linux VM never seems to be able to reconnect successfully - the best way around this is to reboot the VM.","title":"Introduction"},{"location":"linux-workstations/#introduction","text":"This page attempts to outline how you can set up your linux workstation VM to run under VMWare Player Pro V15.0.2 or greater.","title":"Introduction"},{"location":"linux-workstations/#obtaining-vmware-player","text":"If your laptop doesn't have VMware player installed, in the first instance open Software center from the start menu and see if it is available. If it is, install it from here. If it is not available for you in Software Center, speak to service desk (or ideally Matt Page, as he managed this rollout originally) to have this added to your software center.","title":"Obtaining VMWare player"},{"location":"linux-workstations/#obtaining-the-vm-image","text":"The first step of the process is to access the image which is held on: \\\\\\\\business.ukho.gov.uk\\dfs\\Prod_Prod\\Mint\\OVF Image U:\\Prod_Prod\\Mint\\OVF Image and copy this directory to your laptop. Once copied, start up VMware Player Pro and on the \"Home Screen\" select the option \"Open a Virtual Machine\": Please use the file browser displayed to select the location where the image was copied. You will recieve a dialog referring to a mismatch of versions, this is a known bug in VMWare workstation, press Retry and the process will continue. You will be asked for a name and a storage path - please ensure that the name of the VM image is: UKHO CentOS 7 Please ensure that the storage path of the VM image is: C:\\VirtualMachines\\DevVM Danger It is important that the specified location is used for compliance with SyOps!","title":"Obtaining the VM image"},{"location":"linux-workstations/#settings-for-the-vm-image","text":"Ensure the 'tab' for the virtual machine in the UI is selected and click on the 'Edit Virtual Machine Settings' link on the left-hand-side of the page: In the window displayed, select the 'Network Adapter' entry on the left hand side. In the right hand side of the same window, ensure that the following settings are selected under \"Network connection\": \"Bridged\" mode is selected Replicate physical network connection state is selected. Click OK when done.","title":"Settings for the VM image"},{"location":"linux-workstations/#installation-initial-packages","text":"Start-up the Virtual Machine by selecting the \"Power On\" (Ctrl+B) option. You will shortly see a screen having the option \"Install Centos 7 - With Hydro Kickstart\". Press Enter to continue: You will then see a screen which displays \"Press to start the installation process\" - either press Enter (or wait and the install should start automatically. This starts the kickstart installation process. After some minutes (Approx. 7mins, Go grab a lengthy coffee/tea/soft drink) you should see the following: Press return. You will get a message box stating that the machine has halted. Select the \"Restart Guest\" option (or press Ctrl+R) on the VM power settings. Warning Don't try this on UKHO_LAPTOPS wifi, as the setup will not be able to access GitHub After a few minutes the VM should boot and you should be presented with a login prompt: Enter the following: For username: root For password: Example joe.bloggs jane.doe Username constraints The username must be: Lower-case Alphabetic No spaces Next, you will be asked for your full name, which should be alphabetic Next, you will be asked for your password: Warning There are restrictions on the password you can use; passwords which are too lenient will be rejected. The set of interactions (for a user named jane.doe) might look as follows: The installation process will then continue, and you should see a login manager displayed after some time: Press space, this will display a set of users you can log in as (initially, this is the user you created earlier): Login by selecting the name of the user you entered earlier and enter the password, you should be presented with a screen as follows: Initially, this looks a little spartan! You can get an initial desktop created by selecting the 'Use Default Config' option - you should then see something as follows:","title":"Installation - Initial Packages"},{"location":"linux-workstations/#installing-development-utils","text":"Once you have logged in, if you wish to install maven, Java 8 Sdk and Yarn please go to a terminal and type: cd ~/linux-workstation/ansible sudo ansible-playbook -i inventories/laptop-vm/hosts --vault-password-file=$HOME/.config/linux-workstation/.vaultpass development.yml This should then install the basic utilities needed.","title":"Installing development utils"},{"location":"linux-workstations/#known-issues","text":"Bug Currently, the VPN on the Linux VM has an issue if you do the following: Suspend the Linux VM when the laptop is connected to the network via USB-C Resume the Linux VM when the laptop is connected to the network via WiFi Or: Suspend the Linux VM when the laptop is connected to the network via WiFi Resume the Linux VM when the laptop is connected to the network via USB-C Alternatively, keeping the VM un-suspended whilst changing networks avoids this scenario. The issue is that the VPN on the Linux VM never seems to be able to reconnect successfully - the best way around this is to reboot the VM.","title":"Known Issues"},{"location":"open-guidance/contributing-details/","text":"CONTRIBUTING.md Details Provides potential contributors the useful information on how to begin contributing to the project and increase the likelihood of their contribution being accepted. May contain links to the Code of Conduct, purpose/aim of the project, code standards, how to run/build/test etc. Overview The CONTRIBUTING.md is the file that users will normally read before contributing to a project and it must provide them with the information needed to contribute to the project in a style which the owner wants. The CONTRIBUTING.md allows the owner to specify the standards and processes they want contributors to use thus setting the rules for everyone, including the rules for how the owner treats contributors. The CONTRIBUTING.md is (obviously) written in Markdown and placed in the root directory of the repository. If a repo does not have a CONTRIBUTING.md then we do not class it as \"open\" and the owner may not want external contributions Must Have Repo owner (Can be team or individual) Contact details for owner (Email) A welcome/intro paragraph. May Have Link to documentation Link to issue tracker Instructions on how to run tests locally Instructions on how to develop code locally Pull Request process Style guide Where a user can find help Security issue reporting How to report bugs How to request a feature Code of Conduct The recognition model(how people are thanked) Philosophy of the project Versioning process Commit message guidance Definition of done Roadmap Branching conventions Anything else that seems relevant Resources Mozilla tutorial - Good guide on creating/thinking about writing a CONTRIBUTING.MD Template contributing.md - Example base template of a CONTRIBUTING.MD Understanding the InnerSource Checklist - pg. 25 - Creating good house rules for guests: Writing contributing agreements Examples Atom OpenGovernment Rails GitLab","title":"CONTRIBUTING.md Details"},{"location":"open-guidance/contributing-details/#contributingmd-details","text":"Provides potential contributors the useful information on how to begin contributing to the project and increase the likelihood of their contribution being accepted. May contain links to the Code of Conduct, purpose/aim of the project, code standards, how to run/build/test etc.","title":"CONTRIBUTING.md Details"},{"location":"open-guidance/contributing-details/#overview","text":"The CONTRIBUTING.md is the file that users will normally read before contributing to a project and it must provide them with the information needed to contribute to the project in a style which the owner wants. The CONTRIBUTING.md allows the owner to specify the standards and processes they want contributors to use thus setting the rules for everyone, including the rules for how the owner treats contributors. The CONTRIBUTING.md is (obviously) written in Markdown and placed in the root directory of the repository. If a repo does not have a CONTRIBUTING.md then we do not class it as \"open\" and the owner may not want external contributions","title":"Overview"},{"location":"open-guidance/contributing-details/#must-have","text":"Repo owner (Can be team or individual) Contact details for owner (Email) A welcome/intro paragraph.","title":"Must Have"},{"location":"open-guidance/contributing-details/#may-have","text":"Link to documentation Link to issue tracker Instructions on how to run tests locally Instructions on how to develop code locally Pull Request process Style guide Where a user can find help Security issue reporting How to report bugs How to request a feature Code of Conduct The recognition model(how people are thanked) Philosophy of the project Versioning process Commit message guidance Definition of done Roadmap Branching conventions Anything else that seems relevant","title":"May Have"},{"location":"open-guidance/contributing-details/#resources","text":"Mozilla tutorial - Good guide on creating/thinking about writing a CONTRIBUTING.MD Template contributing.md - Example base template of a CONTRIBUTING.MD Understanding the InnerSource Checklist - pg. 25 - Creating good house rules for guests: Writing contributing agreements","title":"Resources"},{"location":"open-guidance/contributing-details/#examples","text":"Atom OpenGovernment Rails GitLab","title":"Examples"},{"location":"open-guidance/migration/","text":"Migrating an existing project As part of the Open Source Governance Checklist , it is a requirement that sensitive data has been removed from the repository history. This can be acheived with Git's filter-branch command to walk over the history of a branch and apply changes throughout. Remove lines from commit messages Gerrit leaves a Commit-Id line in every commit message made. To remove these, the --msg-filter can be used as follows: git filter-branch -f --msg-filter 'sed \"/Change-Id/ d\"' -- --all Substitute Change-Id for any string to match an entire line and delete from all commit message in the branch. Remove directories/files from branch trees To remove directories from the entire history of a branch, use the --tree-filter as follows: git filter-branch --tree-filter \"rm -rf dev\" --prune-empty HEAD","title":"Migrating an existing project"},{"location":"open-guidance/migration/#migrating-an-existing-project","text":"As part of the Open Source Governance Checklist , it is a requirement that sensitive data has been removed from the repository history. This can be acheived with Git's filter-branch command to walk over the history of a branch and apply changes throughout.","title":"Migrating an existing project"},{"location":"open-guidance/migration/#remove-lines-from-commit-messages","text":"Gerrit leaves a Commit-Id line in every commit message made. To remove these, the --msg-filter can be used as follows: git filter-branch -f --msg-filter 'sed \"/Change-Id/ d\"' -- --all Substitute Change-Id for any string to match an entire line and delete from all commit message in the branch.","title":"Remove lines from commit messages"},{"location":"open-guidance/migration/#remove-directoriesfiles-from-branch-trees","text":"To remove directories from the entire history of a branch, use the --tree-filter as follows: git filter-branch --tree-filter \"rm -rf dev\" --prune-empty HEAD","title":"Remove directories/files from branch trees"},{"location":"open-guidance/open-guidance/","text":"Open-Guidance Guidance for what basic documents must be within a repo for open software, aimed to create a common and familiar style. Background This repository is to provide guidance on what must exist in open repos as a minimum with the aim of enabling people to feel familiar when browsing, find information and to become productive if contributing back. Overview All open repos must contain the following: A CONTRIBUTING.md within the root folder. The file is a marker to people that this repo will accept changes from outside of the team. It must contain the processes that the owner of the repository needs people to follow when contributing to the project. Guidance on how to write a CONTRIBUTING.md . A LICENSE within the root folder. This will be MIT in most cases. Having a license is critical as it states what others are allowed to do with the code. A README.md within the root folder. This must contain some basic useful information for the user allowing them to quickly understand the project and get started using it. It isn't the place for extensive documentation. Guidance on what should be in a README.md can be found . A continuous integration build process. Each time a pull request is submitted a build is triggered which will run all the tests to ensure the change does not break any features. This will also give the contributor feedback and confidence that there code will work! Above is the minimum for an what open repo must contain, other useful things a repo may contain: Code of Conduct Code of Conduct from contributor covenant . Changelog Keep a changelog . TDL (Technical decision log) Documenting Architecture Decisions . Architecture Decision Records In action presentation . Scripts script/bootstrap - Configure the machine ready to develop for this repo(pull down and configure dependencies etc.) script/dev - Start any background processes/servers needed during development script/test - Run all the tests for this repo. Code Contribution Process All open repos must be using git and code contributions should be made using the standard Fork and Pull Request approach(or equivalent). Rough guidance on how to make a pull request . Terminology Contributing - This is more than just adding code, this also include creating issues/bug reports, asking questions, improving documentation. Contributor - This refers to anyone who has added to this project, including filing issues. Repo - A git repository and the associated Github/lab with it. Pull Request - How a contributor asks the owner of a repository to accept their contribution. The owner \"pulls\" the contribution into the main repository. Inspiration Alpha Gov - Open Standards","title":"Open-Guidance"},{"location":"open-guidance/open-guidance/#open-guidance","text":"Guidance for what basic documents must be within a repo for open software, aimed to create a common and familiar style.","title":"Open-Guidance"},{"location":"open-guidance/open-guidance/#background","text":"This repository is to provide guidance on what must exist in open repos as a minimum with the aim of enabling people to feel familiar when browsing, find information and to become productive if contributing back.","title":"Background"},{"location":"open-guidance/open-guidance/#overview","text":"All open repos must contain the following: A CONTRIBUTING.md within the root folder. The file is a marker to people that this repo will accept changes from outside of the team. It must contain the processes that the owner of the repository needs people to follow when contributing to the project. Guidance on how to write a CONTRIBUTING.md . A LICENSE within the root folder. This will be MIT in most cases. Having a license is critical as it states what others are allowed to do with the code. A README.md within the root folder. This must contain some basic useful information for the user allowing them to quickly understand the project and get started using it. It isn't the place for extensive documentation. Guidance on what should be in a README.md can be found . A continuous integration build process. Each time a pull request is submitted a build is triggered which will run all the tests to ensure the change does not break any features. This will also give the contributor feedback and confidence that there code will work! Above is the minimum for an what open repo must contain, other useful things a repo may contain: Code of Conduct Code of Conduct from contributor covenant . Changelog Keep a changelog . TDL (Technical decision log) Documenting Architecture Decisions . Architecture Decision Records In action presentation . Scripts script/bootstrap - Configure the machine ready to develop for this repo(pull down and configure dependencies etc.) script/dev - Start any background processes/servers needed during development script/test - Run all the tests for this repo.","title":"Overview"},{"location":"open-guidance/open-guidance/#code-contribution-process","text":"All open repos must be using git and code contributions should be made using the standard Fork and Pull Request approach(or equivalent). Rough guidance on how to make a pull request .","title":"Code Contribution Process"},{"location":"open-guidance/open-guidance/#terminology","text":"Contributing - This is more than just adding code, this also include creating issues/bug reports, asking questions, improving documentation. Contributor - This refers to anyone who has added to this project, including filing issues. Repo - A git repository and the associated Github/lab with it. Pull Request - How a contributor asks the owner of a repository to accept their contribution. The owner \"pulls\" the contribution into the main repository.","title":"Terminology"},{"location":"open-guidance/open-guidance/#inspiration","text":"Alpha Gov - Open Standards","title":"Inspiration"},{"location":"open-guidance/pull-request-details/","text":"Making a Pull Request This is a suggested process, individual repositories will want pull requests to be constructed differently. Check a repos \"CONTRIBUTING.md\" for specific guidelines and ask if you are unsure! Suggested Pull Request Process Clone repository locally Create a new branch off the master branch Make changes with clear commits following good commit guidelines Pull down any changes that might have happened whilst you were making your changes and merge them in locally. Push the branch you made your changes on up to the server Create a pull request from the branch into master A build will be triggered and go green before a PR is accepted The changes will be reviewed by the owners of the repo and can suggest changes Make suggested changes and push them up to the branch again Owner of the repository will accept and merge your changes into master NOTE: If you are making a large feature/architectural changes, open an issue first and discuss it with the owner as they might have additional insights or don't think it is appropriate for the repo. Resources Standard Fork & Pull Request Workflow How To Write The Perfect Pull Request Making A Pull Request GitHub Flow - Really high level Atomic Commits","title":"Making a Pull Request"},{"location":"open-guidance/pull-request-details/#making-a-pull-request","text":"This is a suggested process, individual repositories will want pull requests to be constructed differently. Check a repos \"CONTRIBUTING.md\" for specific guidelines and ask if you are unsure!","title":"Making a Pull Request"},{"location":"open-guidance/pull-request-details/#suggested-pull-request-process","text":"Clone repository locally Create a new branch off the master branch Make changes with clear commits following good commit guidelines Pull down any changes that might have happened whilst you were making your changes and merge them in locally. Push the branch you made your changes on up to the server Create a pull request from the branch into master A build will be triggered and go green before a PR is accepted The changes will be reviewed by the owners of the repo and can suggest changes Make suggested changes and push them up to the branch again Owner of the repository will accept and merge your changes into master NOTE: If you are making a large feature/architectural changes, open an issue first and discuss it with the owner as they might have additional insights or don't think it is appropriate for the repo.","title":"Suggested Pull Request Process"},{"location":"open-guidance/pull-request-details/#resources","text":"Standard Fork & Pull Request Workflow How To Write The Perfect Pull Request Making A Pull Request GitHub Flow - Really high level Atomic Commits","title":"Resources"},{"location":"open-guidance/readme-details/","text":"README.md Details A README.md must provide a user/contributor with a brief summary of the repo and should contain installation steps, basic usage and it's features. The guidelines here are aimed to be applicable regardless of whether the repo is a runnable program, library or framework. Overview The README.md is the first file people look in when evaluating whether to use or contribute to a repo, so when writing them ensure the information is relevant to someone who doesn't know your repo and doesn't care about it. You need to provide just enough information for someone to understand the goals of the repo, download it and get started using it. The README.md is (obviously) written in Markdown and placed in the root directory of the repository. It is not the place for detailed documentation, keep that elsewhere and include links to it. The README.md should also feel familiar, you have probably looked at hundreds of README.md's over the year without realising, try to keep yours in the same style so it feels natural to the reader. Must Have Title of project Introductory paragraph Caveats/Limitations Should Have Demo/Usage (Only very basic) Installation Description of features (this can be rolled into the introductory paragraph) May Have Build badges Single sentence summary Pictures/GIFs How to run the tests How to run the application Link to the license Example HTTP requests/responses (if that kind of repo) Version/Changelog Table of Contents Link to documentation Background context, why have you written this Team members/contributors. Anything else that seems relevant Resources Awesome Readme - An \"awesome-list\" for readme Art Of Readme - Aimed at Node projects but lots of relevant information and philosophy of writing good readme's. GOV.UK Readme Guidance incl Template - A bit heavyweight compared to other advice but relevant and useful. Template Examples Electron-Markdownify HTTPie - Bit long, all documentation is in it. NSGIF Gaze","title":"README.md Details"},{"location":"open-guidance/readme-details/#readmemd-details","text":"A README.md must provide a user/contributor with a brief summary of the repo and should contain installation steps, basic usage and it's features. The guidelines here are aimed to be applicable regardless of whether the repo is a runnable program, library or framework.","title":"README.md Details"},{"location":"open-guidance/readme-details/#overview","text":"The README.md is the first file people look in when evaluating whether to use or contribute to a repo, so when writing them ensure the information is relevant to someone who doesn't know your repo and doesn't care about it. You need to provide just enough information for someone to understand the goals of the repo, download it and get started using it. The README.md is (obviously) written in Markdown and placed in the root directory of the repository. It is not the place for detailed documentation, keep that elsewhere and include links to it. The README.md should also feel familiar, you have probably looked at hundreds of README.md's over the year without realising, try to keep yours in the same style so it feels natural to the reader.","title":"Overview"},{"location":"open-guidance/readme-details/#must-have","text":"Title of project Introductory paragraph Caveats/Limitations","title":"Must Have"},{"location":"open-guidance/readme-details/#should-have","text":"Demo/Usage (Only very basic) Installation Description of features (this can be rolled into the introductory paragraph)","title":"Should Have"},{"location":"open-guidance/readme-details/#may-have","text":"Build badges Single sentence summary Pictures/GIFs How to run the tests How to run the application Link to the license Example HTTP requests/responses (if that kind of repo) Version/Changelog Table of Contents Link to documentation Background context, why have you written this Team members/contributors. Anything else that seems relevant","title":"May Have"},{"location":"open-guidance/readme-details/#resources","text":"Awesome Readme - An \"awesome-list\" for readme Art Of Readme - Aimed at Node projects but lots of relevant information and philosophy of writing good readme's. GOV.UK Readme Guidance incl Template - A bit heavyweight compared to other advice but relevant and useful. Template","title":"Resources"},{"location":"open-guidance/readme-details/#examples","text":"Electron-Markdownify HTTPie - Bit long, all documentation is in it. NSGIF Gaze","title":"Examples"},{"location":"quality-assurance/","text":"UKHO Test Community Docs These documents detail how we work as a Test Community at UKHO. We aim to provide a framework for our testers, developers and community engineers to enable them to deliver testing that supports our desire to build and release good software quickly. Content Our Vision The principles that guide everything we do as a Test Community Our Test Automation Strategy The guidelines for using Test Automation Our Test Standards How we plan, write and organise our tests Our Test Policy UKHO overall testing policy","title":"UKHO Test Community Docs"},{"location":"quality-assurance/#ukho-test-community-docs","text":"These documents detail how we work as a Test Community at UKHO. We aim to provide a framework for our testers, developers and community engineers to enable them to deliver testing that supports our desire to build and release good software quickly.","title":"UKHO Test Community Docs"},{"location":"quality-assurance/#content","text":"Our Vision The principles that guide everything we do as a Test Community Our Test Automation Strategy The guidelines for using Test Automation Our Test Standards How we plan, write and organise our tests Our Test Policy UKHO overall testing policy","title":"Content"},{"location":"quality-assurance/test-automation-strategy/","text":"UKHO Test Automation Strategy Introduction This strategy document details the UKHO approach to test automation. As an organisation we recognise the importance of embracing test automation and utilising it to enable faster development and release of our software products. This strategy acts as a baseline for UKHO development teams, with teams empowered to determine how their teams will adhere to this strategy. This document includes: The UHO Test Automation Model Ways of Working Principles of Automation at UKHO Standards How we measure our progress The UHO Test Automation Model To summarise our approach to test automation we created our take on the standard Test Pyramid Model. This promotes: The areas of testing we aim to automate The correct level in the pyramid we should add testing Principles of Test Automation at UKHO We aim to deliver quality improvement to UKHO development using test automation. We promote that all team using automation should adhere to these principles: New functionality must be covered by passing automated tests (unless there is a legitimate reason not to) Make use of test design patterns and principles Add tests at the correct level of the test pyramid \u2013 lower is better Have a test management process (reviewing execution time, test relevance, code refactoring) for automated tests Test Results are made visible to the team Follow the \u201cgreen tests run\u201d policy All tests should be independent Ways of Working Test automation has provided the opportunity to move away from the traditional developer \u2013 tester divide and move towards an integrated way of working. The following principles are promoted: Use Test Driven Design when developing functionality Pairing developer-tester can improve the development of testing at all levels Follow the UKHO Test Standards when creating automation Processes to manage existing test automation ensure tests remain valid UKHO Test Automation Standards A high-level set of standards acts as a guide for the creation of automated tests: Test Standards How we measure our progress We will maintain metrics to determine our current state of automation at the UKHO. The metrics will be produced by comparing the state of test automation in a product against the exemplar test pyramid. The Future The UKHO Test Community will review and evolve this strategy over time to ensure our approach and ways or working continue to support our development and release processes.","title":"UKHO Test Automation Strategy"},{"location":"quality-assurance/test-automation-strategy/#ukho-test-automation-strategy","text":"","title":"UKHO Test Automation Strategy"},{"location":"quality-assurance/test-automation-strategy/#introduction","text":"This strategy document details the UKHO approach to test automation. As an organisation we recognise the importance of embracing test automation and utilising it to enable faster development and release of our software products. This strategy acts as a baseline for UKHO development teams, with teams empowered to determine how their teams will adhere to this strategy. This document includes: The UHO Test Automation Model Ways of Working Principles of Automation at UKHO Standards How we measure our progress","title":"Introduction"},{"location":"quality-assurance/test-automation-strategy/#the-uho-test-automation-model","text":"To summarise our approach to test automation we created our take on the standard Test Pyramid Model. This promotes: The areas of testing we aim to automate The correct level in the pyramid we should add testing","title":"The UHO Test Automation Model"},{"location":"quality-assurance/test-automation-strategy/#principles-of-test-automation-at-ukho","text":"We aim to deliver quality improvement to UKHO development using test automation. We promote that all team using automation should adhere to these principles: New functionality must be covered by passing automated tests (unless there is a legitimate reason not to) Make use of test design patterns and principles Add tests at the correct level of the test pyramid \u2013 lower is better Have a test management process (reviewing execution time, test relevance, code refactoring) for automated tests Test Results are made visible to the team Follow the \u201cgreen tests run\u201d policy All tests should be independent","title":"Principles of Test Automation at UKHO"},{"location":"quality-assurance/test-automation-strategy/#ways-of-working","text":"Test automation has provided the opportunity to move away from the traditional developer \u2013 tester divide and move towards an integrated way of working. The following principles are promoted: Use Test Driven Design when developing functionality Pairing developer-tester can improve the development of testing at all levels Follow the UKHO Test Standards when creating automation Processes to manage existing test automation ensure tests remain valid","title":"Ways of Working"},{"location":"quality-assurance/test-automation-strategy/#ukho-test-automation-standards","text":"A high-level set of standards acts as a guide for the creation of automated tests: Test Standards","title":"UKHO Test Automation Standards"},{"location":"quality-assurance/test-automation-strategy/#how-we-measure-our-progress","text":"We will maintain metrics to determine our current state of automation at the UKHO. The metrics will be produced by comparing the state of test automation in a product against the exemplar test pyramid.","title":"How we measure our progress"},{"location":"quality-assurance/test-automation-strategy/#the-future","text":"The UKHO Test Community will review and evolve this strategy over time to ensure our approach and ways or working continue to support our development and release processes.","title":"The Future"},{"location":"quality-assurance/test-code-standards/","text":"Test Automation Standards C# and Java Unit Testing API Testing UI Testing Gherkin Test and Defect Management C# and Java Test Automation code should adhere to the same standard as production code Formatting standards should reflect standard in use by development teams (e.g. Google Code Standard, Microsoft) Standard coding principles apply (e.g. SOLID, DRY) Unit Testing Aim for naming consistency. Common standard is to use a When-Then name, for example, WhenTwoItemsExistsThenBothItemsAreReturned Follow best practice: Tests for results not functionality One assertion per test Tests should be isolated, i.e. have no dependencies on other tests nor on order of execution API Testing Perform full happy/unhappy path tests at this level Interactions with APIs should be abstracted into a separate service/facade, not in the test Steps UI Testing Only use for e2e tests or explicit UI features at this level Interactions with UIs should be abstracted into a separate service/facade, not in the test Steps (e.g., Page Object Model) Gherkin Consider whether using Gherkin is required - will it add value or can the extra technical layer be avoided Feature name should reflect the area being tested Scenario name should reflect the purpose of the test, e.g. \u201cEnsure two numbers are added correctly\u201d rather than \u201cadd two numbers\u201d or \u201cadd\u201d Similar scenarios should be in one feature file \u2013 a feature file should only contain similar scenarios Ensure only one result is tested per scenario, try to avoid having too many assertions, better to split into different scenarios Move repeated steps into a Background Perform technical setup and teardown in the Steps classes, not in the Gherkin. Test and Defect Management For C# projects, unit and SpecFlow tests should exist in separate projects Open defects should be managed, a regular team/project review session is recommended","title":"Test Automation Standards"},{"location":"quality-assurance/test-code-standards/#test-automation-standards","text":"C# and Java Unit Testing API Testing UI Testing Gherkin Test and Defect Management","title":"Test Automation Standards"},{"location":"quality-assurance/test-code-standards/#c-and-java","text":"Test Automation code should adhere to the same standard as production code Formatting standards should reflect standard in use by development teams (e.g. Google Code Standard, Microsoft) Standard coding principles apply (e.g. SOLID, DRY)","title":"C# and Java"},{"location":"quality-assurance/test-code-standards/#unit-testing","text":"Aim for naming consistency. Common standard is to use a When-Then name, for example, WhenTwoItemsExistsThenBothItemsAreReturned Follow best practice: Tests for results not functionality One assertion per test Tests should be isolated, i.e. have no dependencies on other tests nor on order of execution","title":"Unit Testing"},{"location":"quality-assurance/test-code-standards/#api-testing","text":"Perform full happy/unhappy path tests at this level Interactions with APIs should be abstracted into a separate service/facade, not in the test Steps","title":"API Testing"},{"location":"quality-assurance/test-code-standards/#ui-testing","text":"Only use for e2e tests or explicit UI features at this level Interactions with UIs should be abstracted into a separate service/facade, not in the test Steps (e.g., Page Object Model)","title":"UI Testing"},{"location":"quality-assurance/test-code-standards/#gherkin","text":"Consider whether using Gherkin is required - will it add value or can the extra technical layer be avoided Feature name should reflect the area being tested Scenario name should reflect the purpose of the test, e.g. \u201cEnsure two numbers are added correctly\u201d rather than \u201cadd two numbers\u201d or \u201cadd\u201d Similar scenarios should be in one feature file \u2013 a feature file should only contain similar scenarios Ensure only one result is tested per scenario, try to avoid having too many assertions, better to split into different scenarios Move repeated steps into a Background Perform technical setup and teardown in the Steps classes, not in the Gherkin.","title":"Gherkin"},{"location":"quality-assurance/test-code-standards/#test-and-defect-management","text":"For C# projects, unit and SpecFlow tests should exist in separate projects Open defects should be managed, a regular team/project review session is recommended","title":"Test and Defect Management"},{"location":"quality-assurance/test-policy/","text":"Purpose and Scope The purpose of this document is to communicate the policy for UKHO for testing of new software, updates, hardware and other related changes. Why do we Test? To build confidence in our systems Detect defects Generate information Manage quality risks To deliver value to our customers How do we measure the effectiveness of testing? Delivery to customers of software and hardware that provides business value. UKHO Long Term Testing Goals To move to a DevOps Model Test Automation provides the bulk of testing functionality High Value manual testing is used Testing across UKHO is done within an Agile framework Who Tests? Test Engineering line manages a group of test engineers, ranging from junior to lead people; they provide testing capability across most of UKHO where testing is carried out within Scrum teams. Outside of the Scrum teams other people do test, for instance within Operations testing of hardware is carried out by the relevant SME, like network engineers carry out network testing. In some non-Agile teams, Business Analysts also carry out testing. Who Manages Testing? The Head of Test line manages all test engineers, but test engineers are task-managed by the overall technology program in conjunction with the Head of Test. Other areas of the business carry out various testing activities, but these people will not necessarily be professional software testers, they are line managed by their relevant program. Roles and Responsibilities of Test Engineering This will only deal with the roles within Test Engineering. In Scope All software applications Any changes to database structures Third-party software Cloud-based applications The Testing Life-Cycle UKHO follows the Disciplined Agile Delivery (DAD) and testing forms part of that lifecycle process which is collectively referred to as the Agile Delivery Governance Framework (ADGF). Testing will be carried out at all stages of development of software and products. There are sub-policies that cover the Agile and Non-Agile methods as well as security, penetration, load and performance testing. The test guidance within the ADGF provides guidance/support for all teams that will carry out testing across UKHO. International Standards Our baseline for standards is ISO/IEC 29119 . Testing Process Followed UKHO follows the fundamental test process as defined by ISTQB.","title":"Purpose and Scope"},{"location":"quality-assurance/test-policy/#purpose-and-scope","text":"The purpose of this document is to communicate the policy for UKHO for testing of new software, updates, hardware and other related changes.","title":"Purpose and Scope"},{"location":"quality-assurance/test-policy/#why-do-we-test","text":"To build confidence in our systems Detect defects Generate information Manage quality risks To deliver value to our customers","title":"Why do we Test?"},{"location":"quality-assurance/test-policy/#how-do-we-measure-the-effectiveness-of-testing","text":"Delivery to customers of software and hardware that provides business value.","title":"How do we measure the effectiveness of testing?"},{"location":"quality-assurance/test-policy/#ukho-long-term-testing-goals","text":"To move to a DevOps Model Test Automation provides the bulk of testing functionality High Value manual testing is used Testing across UKHO is done within an Agile framework","title":"UKHO Long Term Testing Goals"},{"location":"quality-assurance/test-policy/#who-tests","text":"Test Engineering line manages a group of test engineers, ranging from junior to lead people; they provide testing capability across most of UKHO where testing is carried out within Scrum teams. Outside of the Scrum teams other people do test, for instance within Operations testing of hardware is carried out by the relevant SME, like network engineers carry out network testing. In some non-Agile teams, Business Analysts also carry out testing.","title":"Who Tests?"},{"location":"quality-assurance/test-policy/#who-manages-testing","text":"The Head of Test line manages all test engineers, but test engineers are task-managed by the overall technology program in conjunction with the Head of Test. Other areas of the business carry out various testing activities, but these people will not necessarily be professional software testers, they are line managed by their relevant program.","title":"Who Manages Testing?"},{"location":"quality-assurance/test-policy/#roles-and-responsibilities-of-test-engineering","text":"This will only deal with the roles within Test Engineering.","title":"Roles and Responsibilities of Test Engineering"},{"location":"quality-assurance/test-policy/#in-scope","text":"All software applications Any changes to database structures Third-party software Cloud-based applications","title":"In Scope"},{"location":"quality-assurance/test-policy/#the-testing-life-cycle","text":"UKHO follows the Disciplined Agile Delivery (DAD) and testing forms part of that lifecycle process which is collectively referred to as the Agile Delivery Governance Framework (ADGF). Testing will be carried out at all stages of development of software and products. There are sub-policies that cover the Agile and Non-Agile methods as well as security, penetration, load and performance testing. The test guidance within the ADGF provides guidance/support for all teams that will carry out testing across UKHO.","title":"The Testing Life-Cycle"},{"location":"quality-assurance/test-policy/#international-standards","text":"Our baseline for standards is ISO/IEC 29119 .","title":"International Standards"},{"location":"quality-assurance/test-policy/#testing-process-followed","text":"UKHO follows the fundamental test process as defined by ISTQB.","title":"Testing Process Followed"},{"location":"quality-assurance/test-vision/","text":"UKHO Test Vision To Continually Improve our Testing Approach To ensure we use the best testing techniques to deliver Quality Improvement to the One Programme To continually review our approach so we are using the latest technology and techniques. To Automate 100% of what is Automatable Add automation wherever it is possible and applicable, and do so in a consistent manner Ensure we have commonality in technology and practise across the organisation To have Security Testing as an Integral part of our approach Ensure we have the skills and tools to deliver Quality Improvement in security To have security testing part as part of our standard test approach To have a Thriving Test Community Ensure testers have the skills and support to deliver to the UKHO One Programme Promote the value of software testing across the UKHO (including to Development and Citizen Tester communities) Ensure we share knowledge in what we do both internally and externally","title":"UKHO Test Vision"},{"location":"quality-assurance/test-vision/#ukho-test-vision","text":"","title":"UKHO Test Vision"},{"location":"quality-assurance/test-vision/#to-continually-improve-our-testing-approach","text":"To ensure we use the best testing techniques to deliver Quality Improvement to the One Programme To continually review our approach so we are using the latest technology and techniques.","title":"To Continually Improve our Testing Approach"},{"location":"quality-assurance/test-vision/#to-automate-100-of-what-is-automatable","text":"Add automation wherever it is possible and applicable, and do so in a consistent manner Ensure we have commonality in technology and practise across the organisation","title":"To Automate 100% of what is Automatable"},{"location":"quality-assurance/test-vision/#to-have-security-testing-as-an-integral-part-of-our-approach","text":"Ensure we have the skills and tools to deliver Quality Improvement in security To have security testing part as part of our standard test approach","title":"To have Security Testing as an Integral part of our approach"},{"location":"quality-assurance/test-vision/#to-have-a-thriving-test-community","text":"Ensure testers have the skills and support to deliver to the UKHO One Programme Promote the value of software testing across the UKHO (including to Development and Citizen Tester communities) Ensure we share knowledge in what we do both internally and externally","title":"To have a Thriving Test Community"},{"location":"teams/proteus/","text":"Team Proteus Team Proteus is a delivery team currently working on the Data Platform. The team was formerly known as Peppermint but has changed considerably since then to include members from the former Glaciermint team and elsewhere. Members Ildar Galikov - Lead Software Engineer Scott Drayton - Delivery Manager Chris Hall-Palmer - Solution Architect Carl Molyneux - DS&T Representative Antony Derham - Expert Software Engineer/Product Owner Sean Siford - Senior Software Engineer Alex Bush - Senior Software Engineer Benjamin Morgan - Software Engineer Andy Graham - Software Engineer Andy Pickin - Software Engineer Kevin Harragan - Trainee Software Engineer Andy Cleveland - Test Engineer Chris Sutcliffe - DevOps Engineer Principles Delivery efforts made by Team Proteus follow these principles. Use Continuous Delivery - Never build-up work to release Use Design System - All UI work should use components and patterns from the system Use Open Standards - Should be favoured over proprietary lock-in, at least for an interface Use PaaS/SaaS over IaaS/metal - Costs and scalability make these favourable Use cloud over on-prem - Government standard approach Use Slack for communications - More integrations, rest of gov uses Definition of Done Our definition of done must be followed for all work delivered. Sections may only apply to some work. All Work All acceptance criteria are met All tasks are marked as done The boundary of the VNet is not compromised All knowledge transfer complete across team Risks identified and added to RAID log Tech Debt considered and added to Tech Debt log Threat Modelling completed and captured Cost was considered in implementation Software Dev Code review complete Related pull requests merged Continuous integration pipeline written, passing and configured to run appropriate unit test, component test and build jobs Pull Request linked to Azure Board items Appropriate unit/component tests written, passing and executed in build pipeline Container Apps [POST-AB#6335] Should have readiness probe [POST-AB#6349] Should expose appropriate monitoring endpoints [POST-AB#6267] Logging out to appropriate log service App deployment written and deployed by Flux Migrations Tests remain passing after migration Tests re-written where appropriate","title":"Team Proteus"},{"location":"teams/proteus/#team-proteus","text":"Team Proteus is a delivery team currently working on the Data Platform. The team was formerly known as Peppermint but has changed considerably since then to include members from the former Glaciermint team and elsewhere.","title":"Team Proteus"},{"location":"teams/proteus/#members","text":"Ildar Galikov - Lead Software Engineer Scott Drayton - Delivery Manager Chris Hall-Palmer - Solution Architect Carl Molyneux - DS&T Representative Antony Derham - Expert Software Engineer/Product Owner Sean Siford - Senior Software Engineer Alex Bush - Senior Software Engineer Benjamin Morgan - Software Engineer Andy Graham - Software Engineer Andy Pickin - Software Engineer Kevin Harragan - Trainee Software Engineer Andy Cleveland - Test Engineer Chris Sutcliffe - DevOps Engineer","title":"Members"},{"location":"teams/proteus/#principles","text":"Delivery efforts made by Team Proteus follow these principles. Use Continuous Delivery - Never build-up work to release Use Design System - All UI work should use components and patterns from the system Use Open Standards - Should be favoured over proprietary lock-in, at least for an interface Use PaaS/SaaS over IaaS/metal - Costs and scalability make these favourable Use cloud over on-prem - Government standard approach Use Slack for communications - More integrations, rest of gov uses","title":"Principles"},{"location":"teams/proteus/#definition-of-done","text":"Our definition of done must be followed for all work delivered. Sections may only apply to some work.","title":"Definition of Done"},{"location":"teams/proteus/#all-work","text":"All acceptance criteria are met All tasks are marked as done The boundary of the VNet is not compromised All knowledge transfer complete across team Risks identified and added to RAID log Tech Debt considered and added to Tech Debt log Threat Modelling completed and captured Cost was considered in implementation","title":"All Work"},{"location":"teams/proteus/#software-dev","text":"Code review complete Related pull requests merged Continuous integration pipeline written, passing and configured to run appropriate unit test, component test and build jobs Pull Request linked to Azure Board items Appropriate unit/component tests written, passing and executed in build pipeline","title":"Software Dev"},{"location":"teams/proteus/#container-apps","text":"[POST-AB#6335] Should have readiness probe [POST-AB#6349] Should expose appropriate monitoring endpoints [POST-AB#6267] Logging out to appropriate log service App deployment written and deployed by Flux","title":"Container Apps"},{"location":"teams/proteus/#migrations","text":"Tests remain passing after migration Tests re-written where appropriate","title":"Migrations"}]}